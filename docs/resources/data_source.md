---
# generated by https://github.com/hashicorp/terraform-plugin-docs
page_title: "propel_data_source Resource - propel"
subcategory: ""
description: |-
  Provides a Propel Data Source resource. This can be used to create and manage Propel Data Sources.
---

# propel_data_source (Resource)

Provides a Propel Data Source resource. This can be used to create and manage Propel Data Sources.

## Example Usage

```terraform
variable "snowflake_password" {
  type = string
  sensitive = true
}

resource "propel_data_source" "my_data_source" {
  unique_name = "My Snowflake Data Source"
  description = "This is an example of a Snowflake Data Source"
  type        = "SNOWFLAKE"

  snowflake_connection_settings {
    account   = "Snowflake Account"
    database  = "Snowflake Database"
    warehouse = "Snowflake Warehouse"
    schema    = "Snowflake Schema"
    role      = "Snowflake Role"
    username  = "Snowflake Username"
    password  = var.snowflake_password
  }
}

variable "http_basic_auth_password" {
  type = string
  sensitive = true
}

resource "propel_data_source" "my_webhook_data_source" {
  unique_name = "My Webhook Data Source"
  description = "This is an example of a Webhook Data Source"
  type        = "WEBHOOK"
  webhook_connection_settings {
    timestamp = "event_timestamp"
    unique_id = "event_id"
    tenant = "customer_id"
    column {
      name = "event_id"
      type = "STRING"
      nullable = false
      json_property = "event_id"
    }
    column {
      name = "customer_id"
      type = "STRING"
      nullable = false
      json_property = "customer_id"
    }
    column {
      name = "event_timestamp"
      type = "TIMESTAMP"
      nullable = false
      json_property = "event_timestamp"
    }
    column {
      name = "customer_name"
      type = "STRING"
      nullable = true
      json_property = "customer_name"
    }
    basic_auth {
      username = "foo"
      password = var.http_basic_auth_password
    }
  }
}

variable "kafka_password" {
  type = string
  sensitive = true
}

resource "propel_data_source" "my_kafka_data_source" {
  unique_name = "My Kafka Data Source"
  description = "This is an example of a Kafka Data Source"
  type        = "KAFKA"
  kafka_connection_settings {
    auth = "SCRAM-SHA-256"
    user = "user"
    password = var.kafka_password
    tls = true
    bootstrap_servers = ["localhost:9092"]
  }
}

variable "clickhouse_password" {
  type = string
  sensitive = true
}

resource "propel_data_source" "my_clickhouse_data_source" {
  unique_name = "My ClickHouse Data Source"
  description = "This is an example of a ClickHouse Data Source"
  type        = "CLICKHOUSE"
  clickhouse_connection_settings {
    url = "http://127.0.0.1:8123"
    user = "user"
    password = var.clickhouse_password
    database = "sample"
  }
}
```

<!-- schema generated by tfplugindocs -->
## Schema

### Required

- `type` (String) The Data Source's type. Depending on this, you will need to specify one of `snowflake_connection_settings`, `s3_connection_settings`, `http_connection_settings`, `webhook_connection_settings`, `kafka_connection_settings` or `clickhouse_connection_settings`. The valid values are `SNOWFLAKE`, `S3`, `HTTP`, `WEBHOOK`, `KAFKA` and `CLICKHOUSE`

### Optional

- `clickhouse_connection_settings` (Block List, Max: 1) (see [below for nested schema](#nestedblock--clickhouse_connection_settings))
- `description` (String) The Data Source's description.
- `http_connection_settings` (Block List, Max: 1) (see [below for nested schema](#nestedblock--http_connection_settings))
- `kafka_connection_settings` (Block List, Max: 1) (see [below for nested schema](#nestedblock--kafka_connection_settings))
- `s3_connection_settings` (Block List, Max: 1) (see [below for nested schema](#nestedblock--s3_connection_settings))
- `snowflake_connection_settings` (Block List, Max: 1) Snowflake connection settings. Specify these for Snowflake Data Sources. (see [below for nested schema](#nestedblock--snowflake_connection_settings))
- `table` (Block List) (see [below for nested schema](#nestedblock--table))
- `timeouts` (Block, Optional) (see [below for nested schema](#nestedblock--timeouts))
- `unique_name` (String) The Data Source's name.
- `webhook_connection_settings` (Block List, Max: 1) (see [below for nested schema](#nestedblock--webhook_connection_settings))

### Read-Only

- `account` (String) The Account that the Data Source belongs to.
- `created_at` (String) The date and time of when the Data Source was created.
- `created_by` (String) The user who created the Data Source.
- `environment` (String) The Environment that the Data Source belongs to
- `id` (String) The ID of this resource.
- `modified_at` (String) The date and time of when the Data Source was modified.
- `modified_by` (String) The user who modified the Data Source.
- `status` (String) The Data Source's status.

<a id="nestedblock--clickhouse_connection_settings"></a>
### Nested Schema for `clickhouse_connection_settings`

Required:

- `database` (String) Which database to connect to.
- `password` (String, Sensitive) The password for the provided user.
- `url` (String) The URL where the ClickHouse host is listening to HTTP[S] connections.
- `user` (String) The user for authenticating against the ClickHouse host.

Read-Only:

- `readonly` (Boolean) Whether the user has readonly permissions or not for querying ClickHouse.


<a id="nestedblock--http_connection_settings"></a>
### Nested Schema for `http_connection_settings`

Optional:

- `basic_auth` (Block List, Max: 1) The HTTP basic authentication settings. If this parameter is not provided, anyone with the URL will be able to send events. While it's OK to test without HTTP Basic authentication, we recommend enabling it. (see [below for nested schema](#nestedblock--http_connection_settings--basic_auth))

<a id="nestedblock--http_connection_settings--basic_auth"></a>
### Nested Schema for `http_connection_settings.basic_auth`

Required:

- `password` (String, Sensitive) Password for HTTP Basic authentication that must be included in the Authorization header when uploading new data.
- `username` (String) Username for HTTP Basic authentication that must be included in the Authorization header when uploading new data.



<a id="nestedblock--kafka_connection_settings"></a>
### Nested Schema for `kafka_connection_settings`

Required:

- `auth` (String) The type of authentication to use. Can be SCRAM-SHA-256, SCRAM-SHA-512, PLAIN or NONE.
- `bootstrap_servers` (List of String) The bootstrap server(s) to connect to.
- `password` (String, Sensitive) The password for the provided user.
- `user` (String) The user for authenticating against the Kafka servers.

Optional:

- `tls` (Boolean) Whether the the connection to the Kafka servers is encrypted or not.


<a id="nestedblock--s3_connection_settings"></a>
### Nested Schema for `s3_connection_settings`

Required:

- `aws_access_key_id` (String) The AWS access key ID for an IAM user with sufficient access to the S3 bucket.
- `aws_secret_access_key` (String, Sensitive) The AWS secret access key for an IAM user with sufficient access to the S3 bucket.
- `bucket` (String) The name of the S3 bucket.


<a id="nestedblock--snowflake_connection_settings"></a>
### Nested Schema for `snowflake_connection_settings`

Required:

- `account` (String) The Snowflake account. Only include the part before the "snowflakecomputing.com" part of your Snowflake URL (make sure you are in classic console, not Snowsight). For AWS-based accounts, this looks like "znXXXXX.us-east-2.aws". For Google Cloud-based accounts, this looks like "ffXXXXX.us-central1.gcp".
- `database` (String) The Snowflake database name.
- `password` (String, Sensitive) The Snowflake password.
- `role` (String) The Snowflake role. It should be "PROPELLER" if you used the default name in the setup script.
- `schema` (String) The Snowflake schema.
- `username` (String) The Snowflake username. It should be "PROPEL" if you used the default name in the setup script.
- `warehouse` (String) The Snowflake warehouse name. It should be "PROPELLING" if you used the default name in the setup script.


<a id="nestedblock--table"></a>
### Nested Schema for `table`

Required:

- `column` (Block List, Min: 1) Specify a table's columns. (see [below for nested schema](#nestedblock--table--column))
- `name` (String) The name of the table.

Optional:

- `path` (String) The path to the table's files in S3.

Read-Only:

- `id` (String) The table's ID.

<a id="nestedblock--table--column"></a>
### Nested Schema for `table.column`

Required:

- `name` (String) The column name.
- `nullable` (Boolean) Whether the column's type is nullable or not.
- `type` (String) The column type.



<a id="nestedblock--timeouts"></a>
### Nested Schema for `timeouts`

Optional:

- `create` (String)
- `delete` (String)


<a id="nestedblock--webhook_connection_settings"></a>
### Nested Schema for `webhook_connection_settings`

Optional:

- `access_control_enabled` (Boolean) Whether the resulting Data Pool has access control enabled or not. If the Data Pool has access control enabled, Applications must be assigned Data Pool Access Policies in order to query the Data Pool and its Metrics.
- `basic_auth` (Block List, Max: 1) The HTTP basic authentication settings. If this parameter is not provided, anyone with the URL will be able to send events. While it's OK to test without HTTP Basic authentication, we recommend enabling it. (see [below for nested schema](#nestedblock--webhook_connection_settings--basic_auth))
- `column` (Block List) The additional column for the Webhook Data Source table. (see [below for nested schema](#nestedblock--webhook_connection_settings--column))
- `table_settings` (Block List, Max: 1) Override the Data Pool's table settings. These describe how the Data Pool's table is created in ClickHouse, and a default will be chosen based on the Data Pool's `timestamp` and `uniqueId` values, if any. You can override these defaults in order to specify a custom table engine, custom ORDER BY, etc. (see [below for nested schema](#nestedblock--webhook_connection_settings--table_settings))
- `tenant` (String, Deprecated) The tenant ID column, if configured.
- `timestamp` (String) The primary timestamp column.
- `unique_id` (String, Deprecated) The unique ID column. Propel uses the primary timestamp and a unique ID to compose a primary key for determining whether records should be inserted, deleted, or updated.

Read-Only:

- `data_pool_id` (String) The Webhook Data Pool ID.
- `webhook_url` (String) The Webhook URL for posting JSON events.

<a id="nestedblock--webhook_connection_settings--basic_auth"></a>
### Nested Schema for `webhook_connection_settings.basic_auth`

Required:

- `password` (String, Sensitive) Password for HTTP Basic authentication that must be included in the Authorization header when uploading new data.
- `username` (String) Username for HTTP Basic authentication that must be included in the Authorization header when uploading new data.


<a id="nestedblock--webhook_connection_settings--column"></a>
### Nested Schema for `webhook_connection_settings.column`

Required:

- `json_property` (String) The JSON property that the column will be derived from. For example, if you POST a JSON event like this: 

{ "greeting": { "message": "hello, world" } }

Then you can use the JSON property "greeting.message" to extract "hello, world" to a column.
- `name` (String) The column name.
- `nullable` (Boolean) Whether the column's type is nullable or not.
- `type` (String) The column type.


<a id="nestedblock--webhook_connection_settings--table_settings"></a>
### Nested Schema for `webhook_connection_settings.table_settings`

Optional:

- `engine` (Block List, Max: 1) The ClickHouse table engine for the Data Pool's table. This field is optional. A default will be chosen based on the Data Pool's `timestamp` and `uniqueId` values, if specified. (see [below for nested schema](#nestedblock--webhook_connection_settings--table_settings--engine))
- `order_by` (List of String) The ORDER BY clause for the Data Pool's table. This field is optional. A default will be chosen based on the Data Pool's `timestamp` and `uniqueId` values, if specified.
- `partition_by` (List of String) The PARTITION BY clause for the Data Pool's table. This field is optional. A default will be chosen based on the Data Pool's `timestamp` and `uniqueId` values, if specified.
- `primary_key` (List of String) The PRIMARY KEY clause for the Data Pool's table. This field is optional. A default will be chosen based on the Data Pool's `timestamp` and `uniqueId` values, if specified.

<a id="nestedblock--webhook_connection_settings--table_settings--engine"></a>
### Nested Schema for `webhook_connection_settings.table_settings.engine`

Optional:

- `columns` (List of String) The columns argument for the SummingMergeTree table engine.
- `type` (String) The ClickHouse table engine.
- `ver` (String) The `ver` parameter to the ReplacingMergeTree table engine.

## Import

Import is supported using the following syntax:

```shell
terraform import propel_data_source.my_data_source DSO00000000000000000000000000
```
